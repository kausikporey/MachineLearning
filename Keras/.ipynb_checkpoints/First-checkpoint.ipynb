{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44 0.03 0.55 0.44 0.42 0.33] [0.2  0.62 0.3 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "weights = np.round(np.random.uniform(size=(6)),decimals=2)\n",
    "biases = np.round(np.random.uniform(size=(3)),decimals=2)\n",
    "print(weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the input at the first node of the hidden layer is 0.4455\n",
      "The weighted sum of the input at the second node of the hidden layer is 1.2690000000000001\n"
     ]
    }
   ],
   "source": [
    "x1 = 0.5\n",
    "x2 = 0.85\n",
    "z11 = x1*weights[0] + x2*weights[1] + biases[0]\n",
    "print('The weighted sum of the input at the first node of the hidden layer is {}'.format(z11))\n",
    "z12 = x1*weights[2] + x2*weights[3] + biases[1]\n",
    "print('The weighted sum of the input at the second node of the hidden layer is {}'.format(z12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the first node of hidden layer is 0.6095687874858047 and the second node of the hidden layer is 0.7805715163448822\n"
     ]
    }
   ],
   "source": [
    "a11 = 1/(1+np.exp(-z11))\n",
    "a12 = 1/(1+np.exp(-z12))\n",
    "print('Output of the first node of hidden layer is {} and the second node of the hidden layer is {}'.format(a11,a12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813607491137849 0.6928777055737376\n"
     ]
    }
   ],
   "source": [
    "z2 = a11*weights[4] + a12*weights[5] + biases[2]\n",
    "a2 = 1/(1+np.exp(-z2))\n",
    "print(z2,a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_network(num_input_nodes,num_output_nodes,num_hidden_layer,no_node_hidden_layer):\n",
    "    np.random.seed(3)\n",
    "    network = {}\n",
    "    num_nodes_previos_layer = num_input_nodes\n",
    "\n",
    "    for layer in range(num_hidden_layer+1):\n",
    "        if layer == num_hidden_layer:\n",
    "            num_node_incurrent_layer = num_output_nodes\n",
    "        else:\n",
    "            num_node_incurrent_layer = no_node_hidden_layer[layer]\n",
    "\n",
    "\n",
    "        network[layer] = {}\n",
    "        for node in range(num_node_incurrent_layer):\n",
    "            network[layer][node] = {\n",
    "                'weights':np.round(np.random.uniform(size=(num_nodes_previos_layer)),decimals=2),\n",
    "                'bias':np.round(np.random.uniform(size=(1)),decimals=2)\n",
    "            }\n",
    "        num_nodes_previos_layer = num_node_incurrent_layer \n",
    "    return network       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: {'weights': array([0.55, 0.71]), 'bias': array([0.29])}, 1: {'weights': array([0.51, 0.89]), 'bias': array([0.9])}}, 1: {0: {'weights': array([0.13, 0.21]), 'bias': array([0.05])}}}\n"
     ]
    }
   ],
   "source": [
    "no_node_hidden_layer = [2]\n",
    "network = initial_network(2,1,1,no_node_hidden_layer)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(inputs,weights,bias):\n",
    "    value = 0\n",
    "    for i,j in zip(inputs,weights):\n",
    "        value = value + i*j\n",
    "    return value+bias\n",
    "\n",
    "def node_activation(weighted_sum):\n",
    "    return 1/(1+np.exp(-weighted_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(network,input):\n",
    "    inputs = input\n",
    "    activation_value = {}\n",
    "    for layer in network:\n",
    "        activation_value[layer] = {}\n",
    "        next_inputs = []\n",
    "        for node in network[layer]:\n",
    "            node_dict = network[layer][node]\n",
    "            weights = node_dict['weights']\n",
    "            bias = node_dict['bias']\n",
    "            weighted = weighted_sum(inputs,weights,bias)\n",
    "            node_output = node_activation(weighted)\n",
    "            activation_value[layer][node] = {'activation':weighted,'output':node_output}\n",
    "            next_inputs.append(node_output)\n",
    "        inputs = next_inputs    \n",
    "    return next_inputs,activation_value        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.5962827])]\n",
      "{0: {0: {'activation': array([36.64]), 'output': array([1.])}, 1: {'activation': array([45.03]), 'output': array([1.])}}, 1: {0: {'activation': array([0.39]), 'output': array([0.5962827])}}}\n"
     ]
    }
   ],
   "source": [
    "input = [8,45]\n",
    "output,activation = forward_propagation(network,input)\n",
    "print(output)\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55, 0.71, 0.51, 0.89, 0.13, 0.21] [0.29, 0.9, 0.05]\n",
      "The weighted sum of the input at the first node of the hidden layer is 36.64\n",
      "The weighted sum of the input at the second node of the hidden layer is 45.029999999999994\n",
      "Output of the first node of hidden layer is 0.9999999999999998 and the second node of the hidden layer is 1.0\n",
      "0.38999999999999996 0.5962826992967878\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "weights = [0.55,0.71,0.51,0.89,0.13,0.21]\n",
    "biases = [0.29,0.9,0.05]\n",
    "print(weights,biases)\n",
    "x1 = 8\n",
    "x2 = 45\n",
    "z11 = x1*weights[0] + x2*weights[1] + biases[0]\n",
    "print('The weighted sum of the input at the first node of the hidden layer is {}'.format(z11))\n",
    "z12 = x1*weights[2] + x2*weights[3] + biases[1]\n",
    "print('The weighted sum of the input at the second node of the hidden layer is {}'.format(z12))\n",
    "a11 = 1/(1+np.exp(-z11))\n",
    "a12 = 1/(1+np.exp(-z12))\n",
    "print('Output of the first node of hidden layer is {} and the second node of the hidden layer is {}'.format(a11,a12))\n",
    "z2 = a11*weights[4] + a12*weights[5] + biases[2]\n",
    "a2 = 1/(1+np.exp(-z2))\n",
    "print(z2,a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [4. 9.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.empty((2,2))\n",
    "a[0][0] = 1\n",
    "a[0][1] = 2\n",
    "a[1][0] = 4\n",
    "a[1][1] = 9\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit9cd8148d371b4612a82fdac355baf468"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
