{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  3.]\n",
      "  [ 18.]\n",
      "  [ 18.]\n",
      "  [ 18.]\n",
      "  [126.]\n",
      "  [136.]\n",
      "  [175.]\n",
      "  [ 26.]\n",
      "  [166.]\n",
      "  [255.]\n",
      "  [247.]\n",
      "  [127.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 30.]\n",
      "  [ 36.]\n",
      "  [ 94.]\n",
      "  [154.]\n",
      "  [170.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [225.]\n",
      "  [172.]\n",
      "  [253.]\n",
      "  [242.]\n",
      "  [195.]\n",
      "  [ 64.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 49.]\n",
      "  [238.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [251.]\n",
      "  [ 93.]\n",
      "  [ 82.]\n",
      "  [ 82.]\n",
      "  [ 56.]\n",
      "  [ 39.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 18.]\n",
      "  [219.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [198.]\n",
      "  [182.]\n",
      "  [247.]\n",
      "  [241.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 80.]\n",
      "  [156.]\n",
      "  [107.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [205.]\n",
      "  [ 11.]\n",
      "  [  0.]\n",
      "  [ 43.]\n",
      "  [154.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 14.]\n",
      "  [  1.]\n",
      "  [154.]\n",
      "  [253.]\n",
      "  [ 90.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [139.]\n",
      "  [253.]\n",
      "  [190.]\n",
      "  [  2.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 11.]\n",
      "  [190.]\n",
      "  [253.]\n",
      "  [ 70.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 35.]\n",
      "  [241.]\n",
      "  [225.]\n",
      "  [160.]\n",
      "  [108.]\n",
      "  [  1.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 81.]\n",
      "  [240.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [119.]\n",
      "  [ 25.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 45.]\n",
      "  [186.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [150.]\n",
      "  [ 27.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 16.]\n",
      "  [ 93.]\n",
      "  [252.]\n",
      "  [253.]\n",
      "  [187.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [249.]\n",
      "  [253.]\n",
      "  [249.]\n",
      "  [ 64.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 46.]\n",
      "  [130.]\n",
      "  [183.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [207.]\n",
      "  [  2.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 39.]\n",
      "  [148.]\n",
      "  [229.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [250.]\n",
      "  [182.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 24.]\n",
      "  [114.]\n",
      "  [221.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [201.]\n",
      "  [ 78.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 23.]\n",
      "  [ 66.]\n",
      "  [213.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [198.]\n",
      "  [ 81.]\n",
      "  [  2.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 18.]\n",
      "  [171.]\n",
      "  [219.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [195.]\n",
      "  [ 80.]\n",
      "  [  9.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 55.]\n",
      "  [172.]\n",
      "  [226.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [244.]\n",
      "  [133.]\n",
      "  [ 11.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [136.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [212.]\n",
      "  [135.]\n",
      "  [132.]\n",
      "  [ 16.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]]\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255  # normalize training data\n",
    "X_test = X_test/255   # normalize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# let's convert the target variable into binary categories\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_train.shape[1]  # number of categories\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionalModel():\n",
    "    #creating model\n",
    "    model = Sequential()\n",
    "    # 16 is the no of filter we use and(5,5) is the filter size and (1,1) is the value in filter\n",
    "    model.add(Conv2D(16,(5,5),strides=(1,1),activation='relu',input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100,activation='relu')) #fully connected layer\n",
    "    model.add(Dense(num_classes,activation='softmax')) #output layer\n",
    "\n",
    "    #compile model\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 30s - loss: 0.1898 - accuracy: 0.9447 - val_loss: 0.0613 - val_accuracy: 0.9805\n",
      "Epoch 2/10\n",
      "300/300 - 27s - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.0478 - val_accuracy: 0.9849\n",
      "Epoch 3/10\n",
      "300/300 - 27s - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0488 - val_accuracy: 0.9836\n",
      "Epoch 4/10\n",
      "300/300 - 26s - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0372 - val_accuracy: 0.9867\n",
      "Epoch 5/10\n",
      "300/300 - 26s - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0395 - val_accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "300/300 - 29s - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0344 - val_accuracy: 0.9886\n",
      "Epoch 7/10\n",
      "300/300 - 24s - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.0414 - val_accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "300/300 - 24s - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "300/300 - 27s - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "300/300 - 27s - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0403 - val_accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x252d9fff8e0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model = convolutionalModel()\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),verbose=2,epochs=10,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Convolutional_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9882000088691711 \n",
      " Error: 1.1799991130828857\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 19s - loss: 0.4725 - accuracy: 0.8616 - val_loss: 0.1299 - val_accuracy: 0.9613\n",
      "Epoch 2/10\n",
      "300/300 - 16s - loss: 0.1112 - accuracy: 0.9661 - val_loss: 0.0796 - val_accuracy: 0.9741\n",
      "Epoch 3/10\n",
      "300/300 - 16s - loss: 0.0781 - accuracy: 0.9764 - val_loss: 0.0609 - val_accuracy: 0.9798\n",
      "Epoch 4/10\n",
      "300/300 - 17s - loss: 0.0632 - accuracy: 0.9807 - val_loss: 0.0507 - val_accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "300/300 - 16s - loss: 0.0527 - accuracy: 0.9840 - val_loss: 0.0519 - val_accuracy: 0.9848\n",
      "Epoch 6/10\n",
      "300/300 - 16s - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.0434 - val_accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "300/300 - 15s - loss: 0.0407 - accuracy: 0.9878 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
      "Epoch 8/10\n",
      "300/300 - 15s - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.0369 - val_accuracy: 0.9879\n",
      "Epoch 9/10\n",
      "300/300 - 16s - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0377 - val_accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "300/300 - 17s - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0360 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2529aa72040>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9872999787330627 \n",
      " Error: 1.2700021266937256\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Convolutional_Model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit9cd8148d371b4612a82fdac355baf468"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
